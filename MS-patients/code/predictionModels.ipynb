{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"318JEK-aGn2d","outputId":"19f4e652-3d61-4a62-9abd-c463f693868b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd \n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","MS_data1=pd.read_csv('drive/My Drive/Colab Notebooks/final.csv')"]},{"cell_type":"code","source":["'''from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","MS_data1=MS_data1.astype(str)\n","\n","categs_feats = MS_data1[MS_data1.columns[:-1]]\n","encoder = OrdinalEncoder()\n","categs_encoded = encoder.fit_transform(categs_feats)\n","MS_data1[MS_data1.columns[:-1]] = pd.DataFrame(categs_encoded, columns=categs_feats.columns, index=categs_feats.index).astype(int)\n","\n","MSDMT_feat = MS_data1[['Drug name [DrugNameCurrent]']]\n","label_encoder = LabelEncoder()\n","MSDMT_encoded = label_encoder.fit_transform(MSDMT_feat)\n","MS_data1[['Drug name [DrugNameCurrent]']]= pd.DataFrame(MSDMT_encoded, columns=MSDMT_feat.columns, index=MSDMT_feat.index)\n","print(MS_data1.isnull().sum())\n","print(MS_data1.shape)\n","MS_data1'''\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","MS_data1=MS_data1.astype(str)\n","\n","categs_feats = MS_data1[MS_data1.columns.difference(['MSbestcharacterizes'])] #Drug name [DrugNameCurrent]\n","encoder = OrdinalEncoder()\n","categs_encoded = encoder.fit_transform(categs_feats)\n","MS_data1[MS_data1.columns.difference(['MSbestcharacterizes'])] = pd.DataFrame(categs_encoded, columns=categs_feats.columns, index=categs_feats.index).astype(int)\n","\n","label_feat = MS_data1[['MSbestcharacterizes']] #Drug name [DrugNameCurrent]\n","label_encoder = LabelEncoder()\n","label_encoded = label_encoder.fit_transform(label_feat)\n","MS_data1[['MSbestcharacterizes']]= pd.DataFrame(label_encoded, columns=label_feat.columns, index=label_feat.index) #Drug name [DrugNameCurrent]\n","print(MS_data1.isnull().sum())\n","print(MS_data1.shape)\n","MS_data1.rename(columns={'Drug name [DrugNameCurrent]': 'DrugNameCurrent'}, inplace=True)\n","MS_data1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713},"id":"7TG-0o5tG8gt","outputId":"134c4b63-18c4-4735-b988-6c6c4a37c4ee"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["MSbestcharacterizes            0\n","DiagnosticEvoked               0\n","Difficultywalking1             0\n","Difficulybalance               0\n","Shaking1                       0\n","                              ..\n","IVIS_HouseNumbers              0\n","IVIS_LettersNotes              0\n","IVIS_PrintedMaterial           0\n","WasOnAvonex                    0\n","Drug name [DrugNameCurrent]    0\n","Length: 105, dtype: int64\n","(3442, 105)\n"]},{"output_type":"execute_result","data":{"text/plain":["      MSbestcharacterizes  DiagnosticEvoked  Difficultywalking1  \\\n","0                       5                 1                   7   \n","1                       5                 1                   7   \n","2                       4                 0                   3   \n","3                       4                 0                   3   \n","4                       5                 1                   8   \n","...                   ...               ...                 ...   \n","3437                    0                 0                   0   \n","3438                    4                 0                  10   \n","3439                    2                 0                  10   \n","3440                    2                 1                   8   \n","3441                    4                 1                   3   \n","\n","      Difficulybalance  Shaking1  Stiffness1  Weaknessarms  Weaknesslegs1  \\\n","0                    7         0           6             9              7   \n","1                    7         0           6             9              7   \n","2                    3         0           3            11              0   \n","3                    3         0           3            11              0   \n","4                    0        12           0             0              3   \n","...                ...       ...         ...           ...            ...   \n","3437                 5        12          11             2              9   \n","3438                 4        12           6            11              9   \n","3439                 7        12           9             9              8   \n","3440                 7        10           9             9              8   \n","3441                 3        12           3            11              0   \n","\n","      Blindness1  Disturbedvision  ...  BLCS_LostControl  \\\n","0              8                9  ...                 2   \n","1              8                9  ...                 2   \n","2              1               12  ...                 2   \n","3              1               12  ...                 2   \n","4              2                1  ...                 2   \n","...          ...              ...  ...               ...   \n","3437          11               12  ...                 2   \n","3438           7                8  ...                 2   \n","3439          11               12  ...                 0   \n","3440          11               12  ...                 2   \n","3441           0               12  ...                 1   \n","\n","      BWCS_AlteredActivities  BWCS_Constipated  BWCS_Lifestyle  IVIS_Dials  \\\n","0                          0                 2               0           0   \n","1                          0                 2               0           0   \n","2                          0                 0               3           0   \n","3                          0                 0               3           0   \n","4                          0                 4               0           0   \n","...                      ...               ...             ...         ...   \n","3437                       0                 0               0           0   \n","3438                       0                 0               0           0   \n","3439                       0                 0               0           0   \n","3440                       2                 0               6           1   \n","3441                       0                 4               3           0   \n","\n","      IVIS_HouseNumbers  IVIS_LettersNotes  IVIS_PrintedMaterial  WasOnAvonex  \\\n","0                     0                  2                     2            1   \n","1                     0                  2                     2            1   \n","2                     0                  2                     2            0   \n","3                     0                  2                     2            0   \n","4                     0                  0                     0            1   \n","...                 ...                ...                   ...          ...   \n","3437                  0                  0                     0            0   \n","3438                  0                  0                     0            1   \n","3439                  0                  0                     0            1   \n","3440                  2                  1                     1            0   \n","3441                  0                  0                     0            0   \n","\n","      DrugNameCurrent  \n","0                  26  \n","1                  25  \n","2                  15  \n","3                  23  \n","4                   6  \n","...               ...  \n","3437                2  \n","3438               29  \n","3439                2  \n","3440               20  \n","3441               20  \n","\n","[3442 rows x 105 columns]"],"text/html":["\n","  <div id=\"df-fba480ad-8ba8-46b2-8a7b-c59868a69438\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MSbestcharacterizes</th>\n","      <th>DiagnosticEvoked</th>\n","      <th>Difficultywalking1</th>\n","      <th>Difficulybalance</th>\n","      <th>Shaking1</th>\n","      <th>Stiffness1</th>\n","      <th>Weaknessarms</th>\n","      <th>Weaknesslegs1</th>\n","      <th>Blindness1</th>\n","      <th>Disturbedvision</th>\n","      <th>...</th>\n","      <th>BLCS_LostControl</th>\n","      <th>BWCS_AlteredActivities</th>\n","      <th>BWCS_Constipated</th>\n","      <th>BWCS_Lifestyle</th>\n","      <th>IVIS_Dials</th>\n","      <th>IVIS_HouseNumbers</th>\n","      <th>IVIS_LettersNotes</th>\n","      <th>IVIS_PrintedMaterial</th>\n","      <th>WasOnAvonex</th>\n","      <th>DrugNameCurrent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3437</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3438</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>12</td>\n","      <td>6</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>3439</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>12</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3440</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3441</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>12</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3442 rows Ã— 105 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fba480ad-8ba8-46b2-8a7b-c59868a69438')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fba480ad-8ba8-46b2-8a7b-c59868a69438 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fba480ad-8ba8-46b2-8a7b-c59868a69438');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","X1 = MS_data1.drop('MSbestcharacterizes', axis=1) #Drug name [DrugNameCurrent]\n","y1 = MS_data1['MSbestcharacterizes'] #Drug name [DrugNameCurrent]\n","X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=123, test_size=0.10)\n","\n","X2 = MS_data1.drop('MSbestcharacterizes', axis=1) #Drug name [DrugNameCurrent]\n","y2 = MS_data1['MSbestcharacterizes'] #Drug name [DrugNameCurrent]\n","X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=123, test_size=0.20)"],"metadata":{"id":"fx3FJygwHMYg"},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["print('Training data inputs', X1_train.shape)\n","print('Training labels', y1_train.shape)\n","print('Testing data inputs', X1_test.shape)\n","print('Testing labels', y1_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVCe-lpLPTte","outputId":"872cd0eb-cef6-4055-cac5-88c3d816afa9"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data inputs (3097, 104)\n","Training labels (3097,)\n","Testing data inputs (345, 104)\n","Testing labels (345,)\n"]}]},{"cell_type":"code","source":["print('Training data inputs', X2_train.shape)\n","print('Training labels', y2_train.shape)\n","print('Testing data inputs', X2_test.shape)\n","print('Testing labels', y2_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeZH49Yy2Nee","outputId":"f41d4b37-7e1f-41cf-8a90-a8a0ce7d3dc2"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data inputs (2409, 104)\n","Training labels (2409,)\n","Testing data inputs (1033, 104)\n","Testing labels (1033,)\n"]}]},{"cell_type":"code","source":["from itertools import count\n","from statistics import mean\n","from sklearn.metrics import confusion_matrix\n","\n","def class_report(y_test, y_pred):\n","  cm=confusion_matrix(y_test, y_pred)\n","  FP = cm.sum(axis=0) - np.diag(cm) \n","  FN = cm.sum(axis=1) - np.diag(cm)\n","  TP = np.diag(cm)\n","  TN = cm.sum() - (FP + FN + TP)\n","  FP = FP.astype(float)\n","  FN = FN.astype(float)\n","  TP = TP.astype(float)\n","  TN = TN.astype(float)\n","  # Sensitivity, hit rate, recall, or true positive rate\n","  TPR = TP/(TP+FN)\n","  # Specificity or true negative rate\n","  TNR = TN/(TN+FP) \n","  # Precision or positive predictive value\n","  PPV = TP/(TP+FP)\n","  # Negative predictive value\n","  NPV = TN/(TN+FN)\n","  # Fall out or false positive rate\n","  FPR = FP/(FP+TN)\n","  # False negative rate\n","  FNR = FN/(TP+FN)\n","  # False discovery rate\n","  FDR = FP/(TP+FP)\n","  # Overall accuracy for each class\n","  ACC = (TP+TN)/(TP+FP+FN+TN)\n","  # Return Overall Sensitivity Specificity\n","  return mean(TPR), mean(TNR)"],"metadata":{"id":"91D6VuV_jwl6"},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn import neighbors\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import Perceptron\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import StackingClassifier\n","import xgboost as xgb\n","\n","# KNN\n","np.random.seed(0)\n","knn_model = neighbors.KNeighborsClassifier()\n","knn_model.fit(X1_train, y1_train)\n","knn_pred = knn_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, knn_pred)\n","print('The test accuracy of k-Nearest Neighbors is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, knn_pred)\n","print('The test sensitivity and specificity of k-Nearest Neighbors are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# SVC\n","np.random.seed(0)\n","svc_model=SVC() #kernel='linear'\n","svc_model.fit(X1_train, y1_train)\n","svc_pred = svc_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, svc_pred)\n","print('The test accuracy of Support Vector Classifier is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, svc_pred)\n","print('The test sensitivity and specificity of Support Vector Classifier are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Logistic Regression\n","np.random.seed(0)\n","lr_model = LogisticRegression()\n","lr_model.fit(X1_train, y1_train)\n","lr_pred = lr_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, lr_pred)\n","print('The test accuracy of Logistic Regression is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, lr_pred)\n","print('The test sensitivity and specificity of Logistic Regression are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Decision Trees\n","np.random.seed(0)\n","dt_model = DecisionTreeClassifier()\n","dt_model.fit(X1_train, y1_train)\n","dt_pred = dt_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, dt_pred)\n","print('The test accuracy of Decision Tree is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, dt_pred)\n","print('The test sensitivity and specificity of Decision Tree are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Random Forest\n","np.random.seed(0)\n","rf_model = RandomForestClassifier() #n_estimators=50\n","rf_model.fit(X1_train, y1_train)\n","rf_pred = rf_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, rf_pred)\n","print('The test accuracy of Random Forest is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, rf_pred)\n","print('The test sensitivity and specificity of Random Forest are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Naive Bayes\n","np.random.seed(0)\n","nb_model = GaussianNB()\n","nb_model.fit(X1_train, y1_train)\n","nb_pred = nb_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, nb_pred)\n","print('The test accuracy of Naive Bayes is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, nb_pred)\n","print('The test sensitivity and specificity of Naive Bayes are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Perceptron\n","np.random.seed(0)\n","ppn_model = Perceptron() #max_iter=50, eta0=0.7\n","ppn_model.fit(X1_train, y1_train)\n","ppn_pred = ppn_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, ppn_pred)\n","print('The test accuracy of Perceptron is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, ppn_pred)\n","print('The test sensitivity and specificity of Perceptron are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# SGD\n","np.random.seed(0)\n","sgd_model = SGDClassifier() #max_iter=50, loss='hinge', random_state=1\n","sgd_model.fit(X1_train, y1_train)\n","sgd_pred = sgd_model.predict(X1_test)\n","accuracy = accuracy_score(y1_test, sgd_pred)\n","print('The test accuracy of SGD is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, sgd_pred)\n","print('The test sensitivity and specificity of SGD are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Voting \n","np.random.seed(0)\n","voting_classifier = VotingClassifier(\n","    estimators=[('svc', SVC()),\n","                ('dt',DecisionTreeClassifier()),\n","                ('rf', RandomForestClassifier())], \n","    voting='hard') #('knn', knn_model), ('lr',lr_model),\n","voting_classifier.fit(X1_train, y1_train)\n","vc_pred = voting_classifier.predict(X1_test)\n","accuracy = accuracy_score(y1_test, vc_pred)\n","print('The test accuracy of voting_classifier is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y1_test, vc_pred)\n","print('The test sensitivity and specificity of hard voting_classifier are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Bagging\n","np.random.seed(0)\n","bagging_classifier1 = BaggingClassifier(\n","      RandomForestClassifier(), bootstrap=True\n",")\n","bagging_classifier2 = BaggingClassifier(\n","      RandomForestClassifier(), bootstrap=False\n",")\n","bagging_classifier1.fit(X1_train, y1_train)\n","bagging_classifier2.fit(X1_train, y1_train)\n","bagging_preds1 = bagging_classifier1.predict(X1_test)\n","bagging_preds2 = bagging_classifier2.predict(X1_test)\n","bagging_acc1 = accuracy_score(y1_test, bagging_preds1)\n","bagging_acc2 = accuracy_score(y1_test, bagging_preds2)\n","print('Bootstrapping accuracy is {0:7.2f} %'.format(bagging_acc1*100))\n","print('Pasting accuracy is {0:7.2f} %'.format(bagging_acc2*100))\n","report1=class_report(y1_test, bagging_preds1)\n","report2=class_report(y1_test, bagging_preds2)\n","print('Bootstrapping sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report1[1]*100))\n","print('Pasting sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report2[1]*100),'\\n')\n","\n","# Gradient Boosting\n","np.random.seed(0)\n","grad_boost_classifier = GradientBoostingClassifier() #n_estimators=500,learning_rate=0.8,random_state=42,max_depth=2 \n","grad_boost_classifier.fit(X1_train, y1_train)\n","gboost_preds = grad_boost_classifier.predict(X1_test)\n","gboost_acc = accuracy_score(y1_test, gboost_preds)\n","print('Gradient Boosting Ensemble accuracy is {0:7.2f} %'.format(gboost_acc*100))\n","report=class_report(y1_test, gboost_preds)\n","print('The test sensitivity and specificity of Gradient Boosting Ensemble are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# AdaBoost \n","adaboost_classifier = AdaBoostClassifier(\n","    base_estimator=RandomForestClassifier()\n","    )\n","adaboost_classifier.fit(X1_train, y1_train)\n","adaboost_preds = adaboost_classifier.predict(X1_test)\n","adaboost_acc = accuracy_score(y1_test, adaboost_preds)\n","print('AdaBoost Ensemble accuracy is {0:7.2f} %'.format(adaboost_acc*100))\n","report=class_report(y1_test, adaboost_preds)\n","print('AdaBoost sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Stacking \n","np.random.seed(0)\n","base_estimators = [\n","    ('dt', DecisionTreeClassifier()),('rf',RandomForestClassifier())]\n","final_estimator = SVC()\n","stack_classifier = StackingClassifier(estimators = base_estimators, \n","                               final_estimator = final_estimator)\n","stack_classifier.fit(X1_train, y1_train)\n","stack_preds = stack_classifier.predict(X1_test)\n","stack_acc = accuracy_score(y1_test, stack_preds)\n","print('Stacking Ensemble accuracy is {0:7.2f} %'.format(stack_acc*100))\n","report=class_report(y1_test, stack_preds)\n","print('Stacking sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# XGBoost\n","np.random.seed(0)\n","xgb_classifier = xgb.XGBClassifier()\n","xgb_classifier.fit(X1_train, y1_train)\n","xgboost_preds = xgb_classifier.predict(X1_test)\n","xgboost_acc = accuracy_score(y1_test, xgboost_preds)\n","print('XGBoost Ensemble accuracy is {0:7.4f} %'.format(xgboost_acc*100))\n","report=class_report(y1_test, xgboost_preds)\n","print('XGBoost sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8Z3gMV7INBs","outputId":"5571614e-55d1-401c-affd-5288ef1dd2cb"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["The test accuracy of k-Nearest Neighbors is 64.35 %\n","The test sensitivity and specificity of k-Nearest Neighbors are 29.66, 87.14 % \n","\n","The test accuracy of Support Vector Classifier is 71.88 %\n","The test sensitivity and specificity of Support Vector Classifier are 31.05, 88.94 % \n","\n","The test accuracy of Logistic Regression is 70.43 %\n","The test sensitivity and specificity of Logistic Regression are 33.18, 89.58 % \n","\n","The test accuracy of Decision Tree is 64.35 %\n","The test sensitivity and specificity of Decision Tree are 33.55, 89.08 % \n","\n","The test accuracy of Random Forest is 74.78 %\n","The test sensitivity and specificity of Random Forest are 34.33, 89.75 % \n","\n","The test accuracy of Naive Bayes is 40.29 %\n","The test sensitivity and specificity of Naive Bayes are 30.50, 87.46 % \n","\n","The test accuracy of Perceptron is 50.72 %\n","The test sensitivity and specificity of Perceptron are 34.68, 88.54 % \n","\n","The test accuracy of SGD is 68.70 %\n","The test sensitivity and specificity of SGD are 29.22, 88.30 % \n","\n","The test accuracy of voting_classifier is 76.23 %\n","The test sensitivity and specificity of hard voting_classifier are 35.75, 90.40 % \n","\n","Bootstrapping accuracy is   74.78 %\n","Pasting accuracy is   74.20 %\n","Bootstrapping sensitivity and specificity are 35.75, 89.75 %\n","Pasting sensitivity and specificity are 35.75, 89.55 % \n","\n","Gradient Boosting Ensemble accuracy is   75.36 %\n","The test sensitivity and specificity of Gradient Boosting Ensemble are 36.63, 91.32 % \n","\n","AdaBoost Ensemble accuracy is   73.91 %\n","AdaBoost sensitivity and specificity are 32.44, 89.58 % \n","\n","Stacking Ensemble accuracy is   75.07 %\n","Stacking sensitivity and specificity are 34.42, 89.97 % \n","\n","XGBoost Ensemble accuracy is 73.6232 %\n","XGBoost sensitivity and specificity are 34.70, 90.43 % \n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn import neighbors\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import Perceptron\n","from sklearn.linear_model import SGDClassifier\n","\n","# KNN\n","np.random.seed(0)\n","knn_model = neighbors.KNeighborsClassifier()\n","knn_model.fit(X2_train, y2_train)\n","knn_pred = knn_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, knn_pred)\n","print('The test accuracy of k-Nearest Neighbors is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, knn_pred)\n","print('The test sensitivity and specificity of k-Nearest Neighbors are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# SVC\n","np.random.seed(0)\n","svc_model=SVC()\n","svc_model.fit(X2_train, y2_train)\n","svc_pred = svc_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, svc_pred)\n","print('The test accuracy of Support Vector Classifier is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, svc_pred)\n","print('The test sensitivity and specificity of Support Vector Classifier are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Logistic Regression\n","np.random.seed(0)\n","lr_model = LogisticRegression()\n","lr_model.fit(X2_train, y2_train)\n","lr_pred = lr_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, lr_pred)\n","print('The test accuracy of Logistic Regression is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, lr_pred)\n","print('The test sensitivity and specificity of Logistic Regression are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Decision Trees\n","np.random.seed(0)\n","dt_model = DecisionTreeClassifier()\n","dt_model.fit(X2_train, y2_train)\n","dt_pred = dt_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, dt_pred)\n","print('The test accuracy of Decision Tree is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, dt_pred)\n","print('The test sensitivity and specificity of Decision Tree are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Random Forest\n","np.random.seed(0)\n","rf_model = RandomForestClassifier()\n","rf_model.fit(X2_train, y2_train)\n","rf_pred = rf_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, rf_pred)\n","#accuracy2 = rf_model.score(X2_test, y2_test)\n","print('The test accuracy of Random Forest is {0:5.2f} %'.format(accuracy*100))\n","#print('The test accuracy 2 of Random Forest is {0:5.2f} %'.format(accuracy2*100))\n","report=class_report(y2_test, rf_pred)\n","print('The test sensitivity and specificity of Random Forest are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Naive Bayes\n","np.random.seed(0)\n","nb_model = GaussianNB()\n","nb_model.fit(X2_train, y2_train)\n","nb_pred = nb_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, nb_pred)\n","print('The test accuracy of Naive Bayes is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, nb_pred)\n","print('The test sensitivity and specificity of Naive Bayes are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Perceptron\n","np.random.seed(0)\n","ppn_model = Perceptron()\n","ppn_model.fit(X2_train, y2_train)\n","ppn_pred = ppn_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, ppn_pred)\n","print('The test accuracy of Perceptron is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, ppn_pred)\n","print('The test sensitivity and specificity of Perceptron are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# SGD\n","np.random.seed(0)\n","sgd_model = SGDClassifier()\n","sgd_model.fit(X2_train, y2_train)\n","sgd_pred = sgd_model.predict(X2_test)\n","accuracy = accuracy_score(y2_test, sgd_pred)\n","print('The test accuracy of SGD is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, sgd_pred)\n","print('The test sensitivity and specificity of SGD are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Voting \n","np.random.seed(0)\n","voting_classifier = VotingClassifier(\n","    estimators=[('svc', svc_model),\n","                ('dt',dt_model),\n","                ('rf', rf_model)], \n","    voting='hard') #('knn', knn_model), ('lr',lr_model),\n","voting_classifier.fit(X2_train, y2_train)\n","vc_pred = voting_classifier.predict(X2_test)\n","accuracy = accuracy_score(y2_test, vc_pred)\n","print('The test accuracy of voting_classifier is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2_test, vc_pred)\n","print('The test sensitivity and specificity of hard voting_classifier are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Bagging\n","np.random.seed(0)\n","bagging_classifier1 = BaggingClassifier(\n","      RandomForestClassifier(), bootstrap=True\n",")\n","bagging_classifier2 = BaggingClassifier(\n","      RandomForestClassifier(), bootstrap=False\n",")\n","bagging_classifier1.fit(X2_train, y2_train)\n","bagging_classifier2.fit(X2_train, y2_train)\n","bagging_preds1 = bagging_classifier1.predict(X2_test)\n","bagging_preds2 = bagging_classifier2.predict(X2_test)\n","bagging_acc1 = accuracy_score(y2_test, bagging_preds1)\n","bagging_acc2 = accuracy_score(y2_test, bagging_preds2)\n","print('Bootstrapping accuracy is {0:7.2f} %'.format(bagging_acc1*100))\n","print('Pasting accuracy is {0:7.2f} %'.format(bagging_acc2*100))\n","report1=class_report(y2_test, bagging_preds1)\n","report2=class_report(y2_test, bagging_preds2)\n","print('Bootstrapping sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report1[1]*100))\n","print('Pasting sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report2[1]*100),'\\n')\n","\n","# Gradient Boosting\n","np.random.seed(0)\n","grad_boost_classifier = GradientBoostingClassifier() #n_estimators=500,learning_rate=0.8,random_state=42,max_depth=2 \n","grad_boost_classifier.fit(X2_train, y2_train)\n","gboost_preds = grad_boost_classifier.predict(X2_test)\n","gboost_acc = accuracy_score(y2_test, gboost_preds)\n","print('Gradient Boosting Ensemble accuracy is {0:7.2f} %'.format(gboost_acc*100))\n","report=class_report(y2_test, gboost_preds)\n","print('The test sensitivity and specificity of Gradient Boosting Ensemble are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# AdaBoost \n","adaboost_classifier = AdaBoostClassifier(\n","    base_estimator=RandomForestClassifier()\n","    )\n","adaboost_classifier.fit(X2_train, y2_train)\n","adaboost_preds = adaboost_classifier.predict(X2_test)\n","adaboost_acc = accuracy_score(y2_test, adaboost_preds)\n","print('AdaBoost Ensemble accuracy is {0:7.2f} %'.format(adaboost_acc*100))\n","report=class_report(y2_test, adaboost_preds)\n","print('AdaBoost sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Stacking \n","np.random.seed(0)\n","base_estimators = [\n","    ('dt', DecisionTreeClassifier()),('rf',RandomForestClassifier())]\n","final_estimator = SVC()\n","stack_classifier = StackingClassifier(estimators = base_estimators, \n","                               final_estimator = final_estimator)\n","stack_classifier.fit(X2_train, y2_train)\n","stack_preds = stack_classifier.predict(X2_test)\n","stack_acc = accuracy_score(y2_test, stack_preds)\n","print('Stacking Ensemble accuracy is {0:7.2f} %'.format(stack_acc*100))\n","report=class_report(y2_test, stack_preds)\n","print('Stacking sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# XGBoost\n","np.random.seed(0)\n","xgb_classifier = xgb.XGBClassifier()\n","xgb_classifier.fit(X2_train, y2_train)\n","xgboost_preds = xgb_classifier.predict(X2_test)\n","xgboost_acc = accuracy_score(y2_test, xgboost_preds)\n","print('XGBoost Ensemble accuracy is {0:7.4f} %'.format(xgboost_acc*100))\n","report=class_report(y2_test, xgboost_preds)\n","print('XGBoost sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnlsy1HZIn5C","outputId":"b29bddb6-6ef7-4678-b792-a178b5d17276"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["The test accuracy of k-Nearest Neighbors is 61.57 %\n","The test sensitivity and specificity of k-Nearest Neighbors are 27.24, 87.34 % \n","\n","The test accuracy of Support Vector Classifier is 70.38 %\n","The test sensitivity and specificity of Support Vector Classifier are 26.81, 88.61 % \n","\n","The test accuracy of Logistic Regression is 69.41 %\n","The test sensitivity and specificity of Logistic Regression are 31.03, 89.73 % \n","\n","The test accuracy of Decision Tree is 59.92 %\n","The test sensitivity and specificity of Decision Tree are 31.83, 88.54 % \n","\n","The test accuracy of Random Forest is 74.35 %\n","The test sensitivity and specificity of Random Forest are 33.84, 90.42 % \n","\n","The test accuracy of Naive Bayes is 42.69 %\n","The test sensitivity and specificity of Naive Bayes are 32.34, 87.96 % \n","\n","The test accuracy of Perceptron is 65.34 %\n","The test sensitivity and specificity of Perceptron are 22.36, 86.11 % \n","\n","The test accuracy of SGD is 69.41 %\n","The test sensitivity and specificity of SGD are 27.25, 88.32 % \n","\n","The test accuracy of voting_classifier is 74.06 %\n","The test sensitivity and specificity of hard voting_classifier are 33.72, 90.32 % \n","\n","Bootstrapping accuracy is   73.28 %\n","Pasting accuracy is   73.67 %\n","Bootstrapping sensitivity and specificity are 33.72, 89.86 %\n","Pasting sensitivity and specificity are 33.72, 90.15 % \n","\n","Gradient Boosting Ensemble accuracy is   71.35 %\n","The test sensitivity and specificity of Gradient Boosting Ensemble are 34.37, 90.31 % \n","\n","AdaBoost Ensemble accuracy is   73.86 %\n","AdaBoost sensitivity and specificity are 33.97, 90.23 % \n","\n","Stacking Ensemble accuracy is   73.28 %\n","Stacking sensitivity and specificity are 32.09, 90.03 % \n","\n","XGBoost Ensemble accuracy is 72.1200 %\n","XGBoost sensitivity and specificity are 33.79, 90.27 % \n","\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_predict\n","\n","# KNN\n","np.random.seed(0)\n","knn_model = neighbors.KNeighborsClassifier()\n","cv_result = cross_validate(knn_model, X2, y2, cv=5)\n","knn_y_pred = cross_val_predict(knn_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for KNN is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, knn_y_pred)\n","print('The test accuracy of k-Nearest Neighbors is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, knn_y_pred)\n","print('The test sensitivity and specificity of k-Nearest Neighbors are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# SVC\n","np.random.seed(0)\n","svc_model=SVC()\n","cv_result = cross_validate(svc_model, X2, y2, cv=5)\n","svc_y_pred = cross_val_predict(svc_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for SVC is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, svc_y_pred)\n","print('The test accuracy of k-SVC is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, svc_y_pred)\n","print('The test sensitivity and specificity of SVC are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Logistic Regression\n","np.random.seed(0)\n","lr_model = LogisticRegression()\n","cv_result = cross_validate(lr_model, X2, y2, cv=5)\n","lr_y_pred = cross_val_predict(lr_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for Logistic Regression is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, lr_y_pred)\n","print('The test accuracy of Logistic Regression is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, lr_y_pred)\n","print('The test sensitivity and specificity of Logistic Regression are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Decision Trees\n","np.random.seed(0)\n","dt_model = DecisionTreeClassifier()\n","cv_result = cross_validate(dt_model, X2, y2, cv=5)\n","dt_y_pred = cross_val_predict(dt_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for Decision Trees is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, dt_y_pred)\n","print('The test accuracy of Decision Trees is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, dt_y_pred)\n","print('The test sensitivity and specificity of Decision Trees are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Random Forest\n","np.random.seed(0)\n","rf_model = RandomForestClassifier()\n","cv_result = cross_validate(rf_model, X2, y2, cv=5)\n","rf_y_pred = cross_val_predict(rf_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for Random Forest is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, rf_y_pred)\n","print('The test accuracy of Random Forest is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, rf_y_pred)\n","print('The test sensitivity and specificity of Random Forest are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Naive Bayes\n","np.random.seed(0)\n","nb_model = GaussianNB()\n","cv_result = cross_validate(nb_model, X2, y2, cv=5)\n","nb_y_pred = cross_val_predict(nb_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for Naive Bayes is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, nb_y_pred)\n","print('The test accuracy of Naive Bayes is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, nb_y_pred)\n","print('The test sensitivity and specificity of Naive Bayes are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Perceptron\n","np.random.seed(0)\n","ppn_model = Perceptron()\n","cv_result = cross_validate(ppn_model, X2, y2, cv=5)\n","ppn_y_pred = cross_val_predict(ppn_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for Perceptron is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, ppn_y_pred)\n","print('The test accuracy of Perceptron is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, ppn_y_pred)\n","print('The test sensitivity and specificity of Perceptron are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# SGD\n","np.random.seed(0)\n","sgd_model = SGDClassifier()\n","cv_result = cross_validate(sgd_model, X2, y2, cv=5)\n","sgd_y_pred = cross_val_predict(sgd_model, X2, y2, cv=5)\n","scores = cv_result[\"test_score\"]\n","print(\"The mean cross-validation accuracy for SGD is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","accuracy = accuracy_score(y2, sgd_y_pred)\n","print('The test accuracy of SGD is {0:5.2f} %'.format(accuracy*100))\n","report=class_report(y2, sgd_y_pred)\n","print('The test sensitivity and specificity of SGD are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Voting \n","np.random.seed(0)\n","voting_classifier = VotingClassifier(\n","    estimators=[('svc', svc_model),\n","                ('dt',dt_model),\n","                ('rf', rf_model)], \n","    voting='hard') #('knn', knn_model), ('lr',lr_model),\n","voting_classifier_cv = cross_validate(voting_classifier, X2, y2, cv=5)\n","voting_preds = cross_val_predict(voting_classifier, X2, y2, cv=5)\n","scores = voting_classifier_cv[\"test_score\"]\n","print(\"The mean cross-validation accuracy of voting_classifier is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","voting_acc = accuracy_score(y2, voting_preds)\n","print('Gradient Boosting Ensemble accuracy is {0:7.2f} %'.format(gboost_acc*100))\n","report=class_report(y2, voting_preds)\n","print('The test sensitivity and specificity of voting_classifier are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Bagging\n","np.random.seed(0)\n","bagging_classifier1 = BaggingClassifier(\n","      RandomForestClassifier(), bootstrap=True\n",")\n","bagging_classifier2 = BaggingClassifier(\n","      RandomForestClassifier(), bootstrap=False\n",")\n","bagging_classifier1.fit(X2_train, y2_train)\n","bagging_classifier2.fit(X2_train, y2_train)\n","bagging_preds1 = bagging_classifier1.predict(X2_test)\n","bagging_preds2 = bagging_classifier2.predict(X2_test)\n","bagging_classifier_cv1 = cross_validate(bagging_classifier1, X2, y2, cv=5)\n","bagging_classifier_cv2 = cross_validate(bagging_classifier2, X2, y2, cv=5)\n","bagging_preds1 = cross_val_predict(bagging_classifier1, X2, y2, cv=5)\n","bagging_preds2 = cross_val_predict(bagging_classifier2, X2, y2, cv=5)\n","scores1 = bagging_classifier_cv1[\"test_score\"]\n","print(\"The mean cross-validation accuracy of Bootstrapping is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","scores2 = bagging_classifier_cv2[\"test_score\"]\n","print(\"The mean cross-validation accuracy of Pasting is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","bagging_acc1 = accuracy_score(y2, bagging_preds1)\n","bagging_acc2 = accuracy_score(y2, bagging_preds2)\n","print('Bootstrapping accuracy is {0:7.2f} %'.format(bagging_acc1*100))\n","print('Pasting accuracy is {0:7.2f} %'.format(bagging_acc2*100))\n","report1=class_report(y2, bagging_preds1)\n","report2=class_report(y2, bagging_preds2)\n","print('Bootstrapping sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report1[1]*100))\n","print('Pasting sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report2[1]*100),'\\n')\n","\n","# Gradient Boosting\n","np.random.seed(0)\n","grad_boost_classifier = GradientBoostingClassifier() #n_estimators=500,learning_rate=0.8,random_state=42,max_depth=2 \n","grad_boost_cv = cross_validate(grad_boost_classifier, X2, y2, cv=5)\n","gboost_preds = cross_val_predict(grad_boost_classifier, X2, y2, cv=5)\n","scores = grad_boost_cv[\"test_score\"]\n","print(\"The mean cross-validation accuracy of Gradient Boosting classifier is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","gboost_acc = accuracy_score(y2, gboost_preds)\n","print('Gradient Boosting Ensemble accuracy is {0:7.2f} %'.format(gboost_acc*100))\n","report=class_report(y2, gboost_preds)\n","print('The test sensitivity and specificity of Gradient Boosting classifier are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# AdaBoost \n","adaboost_classifier = AdaBoostClassifier(\n","    base_estimator=RandomForestClassifier()\n","    )\n","ada_boost_cv = cross_validate(adaboost_classifier, X2, y2, cv=5)\n","ada_preds = cross_val_predict(adaboost_classifier, X2, y2, cv=5)\n","scores = ada_boost_cv[\"test_score\"]\n","print(\"The mean cross-validation accuracy of AdaBoost classifier is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","adaboost_acc = accuracy_score(y2, ada_preds)\n","print('AdaBoost Ensemble accuracy is {0:7.2f} %'.format(adaboost_acc*100))\n","report=class_report(y2, ada_preds)\n","print('AdaBoost sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# Stacking \n","np.random.seed(0)\n","base_estimators = [\n","    ('dt', DecisionTreeClassifier()),('rf',RandomForestClassifier())]\n","final_estimator = SVC()\n","stack_classifier = StackingClassifier(estimators = base_estimators, \n","                               final_estimator = final_estimator)\n","stack_boost_cv = cross_validate(stack_classifier, X2, y2, cv=5)\n","stack_preds = cross_val_predict(stack_classifier, X2, y2, cv=5)\n","scores = stack_boost_cv[\"test_score\"]\n","print(\"The mean cross-validation accuracy of Stacking classifier is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","stack_acc = accuracy_score(y2, stack_preds)\n","print('Stacking Ensemble accuracy is {0:7.2f} %'.format(stack_acc*100))\n","report=class_report(y2, stack_preds)\n","print('Stacking sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')\n","\n","# XGBoost\n","np.random.seed(0)\n","xgb_classifier = xgb.XGBClassifier()\n","xgboost_cv = cross_validate(xgb_classifier, X2, y2, cv=5)\n","xgboost_preds = cross_val_predict(xgb_classifier, X2, y2, cv=5)\n","scores = xgboost_cv[\"test_score\"]\n","print(\"The mean cross-validation accuracy of XGBoost classifier is: \"\n","      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n","xgboost_acc = accuracy_score(y2, xgboost_preds)\n","print('XGBoost Ensemble accuracy is {0:7.4f} %'.format(xgboost_acc*100))\n","report=class_report(y2, xgboost_preds)\n","print('XGBoost sensitivity and specificity are {0:.2f}, {1:.2f} %'.format(report[0]*100,report[1]*100),'\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_XRCoFBRUJc","outputId":"a6227598-812c-4165-8f0f-121a6e457a56"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean cross-validation accuracy for KNN is: 0.598 +/- 0.010\n","The test accuracy of k-Nearest Neighbors is 59.85 %\n","The test sensitivity and specificity of k-Nearest Neighbors are 26.06, 86.48 % \n","\n","The mean cross-validation accuracy for SVC is: 0.685 +/- 0.006\n","The test accuracy of k-SVC is 68.54 %\n","The test sensitivity and specificity of SVC are 24.80, 87.70 % \n","\n","The mean cross-validation accuracy for Logistic Regression is: 0.670 +/- 0.017\n","The test accuracy of Logistic Regression is 66.97 %\n","The test sensitivity and specificity of Logistic Regression are 28.29, 88.70 % \n","\n","The mean cross-validation accuracy for Decision Trees is: 0.551 +/- 0.011\n","The test accuracy of Decision Trees is 55.11 %\n","The test sensitivity and specificity of Decision Trees are 26.58, 87.51 % \n","\n","The mean cross-validation accuracy for Random Forest is: 0.695 +/- 0.014\n","The test accuracy of Random Forest is 69.49 %\n","The test sensitivity and specificity of Random Forest are 27.28, 88.36 % \n","\n","The mean cross-validation accuracy for Naive Bayes is: 0.392 +/- 0.041\n","The test accuracy of Naive Bayes is 39.16 %\n","The test sensitivity and specificity of Naive Bayes are 28.87, 87.22 % \n","\n","The mean cross-validation accuracy for Perceptron is: 0.594 +/- 0.066\n","The test accuracy of Perceptron is 59.41 %\n","The test sensitivity and specificity of Perceptron are 25.54, 87.74 % \n","\n","The mean cross-validation accuracy for SGD is: 0.631 +/- 0.048\n","The test accuracy of SGD is 59.36 %\n","The test sensitivity and specificity of SGD are 29.74, 88.64 % \n","\n","The mean cross-validation accuracy of voting_classifier is: 0.694 +/- 0.014\n","Gradient Boosting Ensemble accuracy is   71.35 %\n","The test sensitivity and specificity of voting_classifier are 27.24, 88.30 % \n","\n","The mean cross-validation accuracy of Bootstrapping is: 0.694 +/- 0.014\n","The mean cross-validation accuracy of Pasting is: 0.694 +/- 0.014\n","Bootstrapping accuracy is   69.49 %\n","Pasting accuracy is   69.73 %\n","Bootstrapping sensitivity and specificity are 27.24, 88.11 %\n","Pasting sensitivity and specificity are 27.24, 88.33 % \n","\n","The mean cross-validation accuracy of Gradient Boosting classifier is: 0.695 +/- 0.015\n","Gradient Boosting Ensemble accuracy is   69.20 %\n","The test sensitivity and specificity of Gradient Boosting classifier are 30.58, 89.24 % \n","\n","The mean cross-validation accuracy of AdaBoost classifier is: 0.694 +/- 0.019\n","AdaBoost Ensemble accuracy is   69.35 %\n","AdaBoost sensitivity and specificity are 27.24, 88.22 % \n","\n","The mean cross-validation accuracy of Stacking classifier is: 0.687 +/- 0.015\n","Stacking Ensemble accuracy is   69.17 %\n","Stacking sensitivity and specificity are 26.67, 88.15 % \n","\n","The mean cross-validation accuracy of XGBoost classifier is: 0.703 +/- 0.013\n","XGBoost Ensemble accuracy is 70.2499 %\n","XGBoost sensitivity and specificity are 29.99, 89.24 % \n","\n"]}]},{"cell_type":"code","source":["xfrom sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import uniform, randint\n","\n","np.random.seed(0)\n","rf_model = RandomForestClassifier(random_state=123)\n","hyper_distributions = {\n","    'n_estimators': randint(20, 1000),\n","    'max_depth': randint(4, 200),\n","    'min_samples_leaf': randint(1, 1000),\n","}\n","random_search_2 = RandomizedSearchCV(rf_model, hyper_distributions, n_iter=20, scoring='accuracy')\n","results = random_search_2.fit(X1_train, y1_train)\n","print('Accuracy:',results.best_score_)\n","print('Hyperparameters:', results.best_params_)"],"metadata":{"id":"WpXpu8s8PJiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n","# Number of features to consider at every split\n","max_features = ['auto', 'sqrt']\n","# Maximum number of levels in tree\n","max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","max_depth.append(None)\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10]\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = [1, 2, 4]\n","# Method of selecting samples for training each tree\n","bootstrap = [True, False]\n","# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf,\n","               'bootstrap': bootstrap}\n","print(random_grid)\n","# Use the random grid to search for best hyperparameters\n","# First create the base model to tune\n","rf = RandomForestClassifier()\n","# Random search of parameters, using 3 fold cross validation, \n","# search across 100 different combinations, and use all available cores\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n","# Fit the random search model\n","rf_random.fit(X1_train, y1_train)\n","print('Accuracy:',rf_random.best_score_)\n","print('Hyperparameters:', rf_random.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eT4nyXN_0iS6","outputId":"092e2317-c5a5-41ba-d870-b99a339540c5"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n","Fitting 3 folds for each of 100 candidates, totalling 300 fits\n","Accuracy: 0.7261888681270027\n","Hyperparameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': False}\n"]}]},{"cell_type":"code","source":["def _report(TN, FP, FN, TP):\n","    TPR = TP/(TP+FN) if (TP+FN)!=0 else 0\n","    TNR = TN/(TN+FP) if (TN+FP)!=0 else 0\n","    PPV = TP/(TP+FP) if (TP+FP)!=0 else 0\n","    report = {'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN, \n","              'TPR': TPR, 'Recall': TPR, 'Sensitivity': TPR,\n","              'TNR' : TNR, 'Specificity': TNR,\n","              'FPR': FP/(FP+TN) if (FP+TN)!=0 else 0,\n","              'FNR': FN/(FN+TP) if (FN+TP)!=0 else 0,\n","              'PPV': PPV, 'Precision': PPV,\n","              'F1 Score': 2*(PPV*TPR)/(PPV+TPR)\n","             }\n","    return report\n","\n","def multi_classification_report(y_test, y_pred, labels=None, encoded_labels=True, as_frame=False):\n","    \"\"\"\n","    Args:\n","        y_true (ndarray)\n","        y_pred (ndarray)\n","        labels (list)\n","        encoded_labels (bool): Need to be False if labels are not one hot encoded\n","        as_fram (bool): If True, return type will be DataFrame\n","        \n","    Return:\n","        report (dict)\n","    \"\"\"\n","    \n","    import numpy as np\n","    import pandas as pd\n","    from sklearn.metrics import multilabel_confusion_matrix\n","    \n","    conf_labels = None if encoded_labels else labels\n","    \n","    conf_mat = multilabel_confusion_matrix(y_test, y_pred, labels=conf_labels)\n","    report = dict()\n","    if labels == None:\n","        counter = np.arange(len(conf_mat))\n","    else:\n","        counter = labels\n","        \n","    for i, name in enumerate(counter):\n","        TN, FP, FN, TP = conf_mat[i].ravel()\n","        report[name] = _report(TN, FP, FN, TP)\n","    \n","    if as_frame:\n","        return pd.DataFrame(report)\n","    return report"],"metadata":{"id":"4WGhbF9UIZo5"},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class_report=multi_classification_report(y2_test, rf_pred, encoded_labels=True, as_frame=True)\n","class_report"],"metadata":{"id":"LCxswsMMJmve","colab":{"base_uri":"https://localhost:8080/","height":488},"outputId":"c58163ef-709b-4832-93a7-9d4747e8bbd3"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      0            1           2       3           4  \\\n","TP             1.000000     5.000000   36.000000     0.0  613.000000   \n","TN           994.000000  1006.000000  905.000000  1030.0  200.000000   \n","FP             1.000000     0.000000   18.000000     0.0  185.000000   \n","FN            37.000000    22.000000   74.000000     3.0   35.000000   \n","TPR            0.026316     0.185185    0.327273     0.0    0.945988   \n","Recall         0.026316     0.185185    0.327273     0.0    0.945988   \n","Sensitivity    0.026316     0.185185    0.327273     0.0    0.945988   \n","TNR            0.998995     1.000000    0.980498     1.0    0.519481   \n","Specificity    0.998995     1.000000    0.980498     1.0    0.519481   \n","FPR            0.001005     0.000000    0.019502     0.0    0.480519   \n","FNR            0.973684     0.814815    0.672727     1.0    0.054012   \n","PPV            0.500000     1.000000    0.666667     0.0    0.768170   \n","Precision      0.500000     1.000000    0.666667     0.0    0.768170   \n","F1 Score       0.050000     0.312500    0.439024     NaN    0.847856   \n","\n","                      5  \n","TP           113.000000  \n","TN           765.000000  \n","FP            61.000000  \n","FN            94.000000  \n","TPR            0.545894  \n","Recall         0.545894  \n","Sensitivity    0.545894  \n","TNR            0.926150  \n","Specificity    0.926150  \n","FPR            0.073850  \n","FNR            0.454106  \n","PPV            0.649425  \n","Precision      0.649425  \n","F1 Score       0.593176  "],"text/html":["\n","  <div id=\"df-693b270e-2efe-4802-829b-3fc68b611d4d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>TP</th>\n","      <td>1.000000</td>\n","      <td>5.000000</td>\n","      <td>36.000000</td>\n","      <td>0.0</td>\n","      <td>613.000000</td>\n","      <td>113.000000</td>\n","    </tr>\n","    <tr>\n","      <th>TN</th>\n","      <td>994.000000</td>\n","      <td>1006.000000</td>\n","      <td>905.000000</td>\n","      <td>1030.0</td>\n","      <td>200.000000</td>\n","      <td>765.000000</td>\n","    </tr>\n","    <tr>\n","      <th>FP</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>18.000000</td>\n","      <td>0.0</td>\n","      <td>185.000000</td>\n","      <td>61.000000</td>\n","    </tr>\n","    <tr>\n","      <th>FN</th>\n","      <td>37.000000</td>\n","      <td>22.000000</td>\n","      <td>74.000000</td>\n","      <td>3.0</td>\n","      <td>35.000000</td>\n","      <td>94.000000</td>\n","    </tr>\n","    <tr>\n","      <th>TPR</th>\n","      <td>0.026316</td>\n","      <td>0.185185</td>\n","      <td>0.327273</td>\n","      <td>0.0</td>\n","      <td>0.945988</td>\n","      <td>0.545894</td>\n","    </tr>\n","    <tr>\n","      <th>Recall</th>\n","      <td>0.026316</td>\n","      <td>0.185185</td>\n","      <td>0.327273</td>\n","      <td>0.0</td>\n","      <td>0.945988</td>\n","      <td>0.545894</td>\n","    </tr>\n","    <tr>\n","      <th>Sensitivity</th>\n","      <td>0.026316</td>\n","      <td>0.185185</td>\n","      <td>0.327273</td>\n","      <td>0.0</td>\n","      <td>0.945988</td>\n","      <td>0.545894</td>\n","    </tr>\n","    <tr>\n","      <th>TNR</th>\n","      <td>0.998995</td>\n","      <td>1.000000</td>\n","      <td>0.980498</td>\n","      <td>1.0</td>\n","      <td>0.519481</td>\n","      <td>0.926150</td>\n","    </tr>\n","    <tr>\n","      <th>Specificity</th>\n","      <td>0.998995</td>\n","      <td>1.000000</td>\n","      <td>0.980498</td>\n","      <td>1.0</td>\n","      <td>0.519481</td>\n","      <td>0.926150</td>\n","    </tr>\n","    <tr>\n","      <th>FPR</th>\n","      <td>0.001005</td>\n","      <td>0.000000</td>\n","      <td>0.019502</td>\n","      <td>0.0</td>\n","      <td>0.480519</td>\n","      <td>0.073850</td>\n","    </tr>\n","    <tr>\n","      <th>FNR</th>\n","      <td>0.973684</td>\n","      <td>0.814815</td>\n","      <td>0.672727</td>\n","      <td>1.0</td>\n","      <td>0.054012</td>\n","      <td>0.454106</td>\n","    </tr>\n","    <tr>\n","      <th>PPV</th>\n","      <td>0.500000</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.768170</td>\n","      <td>0.649425</td>\n","    </tr>\n","    <tr>\n","      <th>Precision</th>\n","      <td>0.500000</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.768170</td>\n","      <td>0.649425</td>\n","    </tr>\n","    <tr>\n","      <th>F1 Score</th>\n","      <td>0.050000</td>\n","      <td>0.312500</td>\n","      <td>0.439024</td>\n","      <td>NaN</td>\n","      <td>0.847856</td>\n","      <td>0.593176</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-693b270e-2efe-4802-829b-3fc68b611d4d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-693b270e-2efe-4802-829b-3fc68b611d4d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-693b270e-2efe-4802-829b-3fc68b611d4d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import plot_confusion_matrix\n","\n","disp = plot_confusion_matrix(rf_model, X2_test, y2_test,\n","                                 #display_labels=class_names,\n","                                 cmap=plt.cm.Blues)\n","plt.show()"],"metadata":{"id":"X0TKGqHLuiMM"},"execution_count":null,"outputs":[]}]}
